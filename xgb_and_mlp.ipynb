{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "import traceback\n",
    "\n",
    "import torch.nn as nn\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85450, 21)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pl.read_csv('features.csv')\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((85450, 20), (85450,))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all = df_all.drop('LABEL').to_numpy()\n",
    "y_all = df_all['LABEL'].apply(lambda y: 0 if y == -1 else 1).to_numpy()\n",
    "X_all.shape, y_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.33, random_state=447128, shuffle=True, stratify=y_all)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92     19321\n",
      "           1       0.84      0.84      0.84      8878\n",
      "\n",
      "    accuracy                           0.90     28199\n",
      "   macro avg       0.88      0.88      0.88     28199\n",
      "weighted avg       0.90      0.90      0.90     28199\n",
      "\n",
      "Time taken = 5.257s\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(objective=\"binary:logistic\", random_state=6786122)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "pred_values = xgb_model.predict(X_test)\n",
    "pred_labels = np.round(pred_values)\n",
    "\n",
    "print(classification_report(y_test, pred_labels))\n",
    "delta_time = time() - start\n",
    "print(f'Time taken = {delta_time:.3f}s')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment variables\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\"\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "N_EPOCHS = 300\n",
    "LEARNING_RATE = 0.0005\n",
    "DROPOUT_RATE = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc1 = nn.Linear(20, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp(\n",
    "        model: nn.Module, \n",
    "        dataloader_train: DataLoader, \n",
    "        criterion,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        n_epochs: int,\n",
    "        X_valid: torch.Tensor,\n",
    "        y_valid: torch.Tensor):\n",
    "    # Load validation set to device\n",
    "    X_valid = X_valid.to(DEVICE)\n",
    "    y_valid = y_valid.to(DEVICE)\n",
    "\n",
    "    train_loss_history = []\n",
    "    valid_loss_history = []\n",
    "\n",
    "    start_time = time()\n",
    "    for epoch in range(n_epochs):\n",
    "        running_train_loss = 0.0\n",
    "        # Batches\n",
    "        for inputs, labels in tqdm(dataloader_train):\n",
    "            model.train()\n",
    "            # Copy batch to device\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "\n",
    "            # Rremove gradients from previous batch\n",
    "            optimizer.zero_grad()\n",
    "            # Predict using current model state\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute batch loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Backpropagate\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Add training loss\n",
    "            running_train_loss += loss.item()\n",
    "        # Epoch training loss (divide by num of batches)\n",
    "        epoch_train_loss = running_train_loss / len(dataloader_train) \n",
    "        train_loss_history.append(epoch_train_loss)\n",
    "\n",
    "        # Epoch validation loss\n",
    "        with torch.inference_mode():\n",
    "            outputs_valid = model(X_valid)\n",
    "            epoch_valid_loss = criterion(outputs_valid, y_valid).item()\n",
    "            # epoch_valid_loss = loss_valid.item() * X_valid.size(0)\n",
    "            valid_loss_history.append(epoch_valid_loss)\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}: Train Loss = {epoch_train_loss:.4f}, Validation Loss = {epoch_valid_loss:.4f}\")\n",
    "\n",
    "    print(f\"Took {time() - start_time:.2f} seconds to train in total\")\n",
    "    return train_loss_history, valid_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model_with_logit: nn.Module, X: torch.Tensor) -> torch.Tensor:\n",
    "    was_training = model_with_logit.training\n",
    "    model_with_logit.eval()\n",
    "    with torch.inference_mode():\n",
    "        # Predicted probabilities\n",
    "        pred_probs = torch.sigmoid(model_with_logit(X.to(DEVICE)))\n",
    "    # Predicted labels\n",
    "    if was_training is True:\n",
    "        model_with_logit.train()\n",
    "    return torch.round(pred_probs)\n",
    "\n",
    "def predict_probs(model_with_logit: nn.Module, X: torch.Tensor) -> torch.Tensor:\n",
    "    was_training = model_with_logit.training\n",
    "    model_with_logit.eval()\n",
    "    with torch.inference_mode():\n",
    "        # Predicted probabilities\n",
    "        pred_probs = torch.sigmoid(model_with_logit(X.to(DEVICE)))\n",
    "    # Predicted labels\n",
    "    if was_training is True:\n",
    "        model_with_logit.train()\n",
    "    return pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model_with_logit: nn.Module, X: torch.Tensor, y: torch.Tensor):\n",
    "    X = X.to(DEVICE)\n",
    "    y = y.to(DEVICE)\n",
    "    # Predict labels using model\n",
    "    pred_labels = predict(model_with_logit, X).to('cpu')\n",
    "    X = X.to('cpu')\n",
    "    y = y.to('cpu')\n",
    "    # Compare predicted with ground truth\n",
    "    is_equal_tensor = torch.eq(pred_labels.squeeze(), y.squeeze())\n",
    "    accuracy = is_equal_tensor.sum() / len(X)\n",
    "\n",
    "    diff = (pred_labels.squeeze() - y.squeeze())\n",
    "    fpos = diff[diff == -1].shape[0]\n",
    "    fneg = diff[diff == 1].shape[0]\n",
    "    \n",
    "    return accuracy.item(), fpos, fneg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1790/1790 [00:07<00:00, 240.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: Train Loss = 4.8669, Validation Loss = 0.7831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1790/1790 [00:06<00:00, 262.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: Train Loss = 0.8089, Validation Loss = 1.0413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1790/1790 [00:06<00:00, 261.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: Train Loss = 0.7304, Validation Loss = 0.7306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1790/1790 [00:06<00:00, 260.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: Train Loss = 0.6670, Validation Loss = 0.6594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1790/1790 [00:06<00:00, 256.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: Train Loss = 0.6421, Validation Loss = 0.6453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1790/1790 [00:06<00:00, 256.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: Train Loss = 0.6071, Validation Loss = 0.5979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1790/1790 [00:06<00:00, 264.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: Train Loss = 0.5918, Validation Loss = 0.5753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1790/1790 [00:06<00:00, 265.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: Train Loss = 0.5817, Validation Loss = 0.5662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1790/1790 [00:06<00:00, 265.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: Train Loss = 0.5798, Validation Loss = 0.5666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1790/1790 [00:06<00:00, 270.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: Train Loss = 0.5757, Validation Loss = 0.5818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1790/1790 [00:06<00:00, 272.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: Train Loss = 0.5727, Validation Loss = 0.5879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1790/1790 [00:06<00:00, 270.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: Train Loss = 0.5746, Validation Loss = 0.5638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1790/1790 [00:06<00:00, 271.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: Train Loss = 0.5709, Validation Loss = 0.5616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1790/1790 [00:06<00:00, 272.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: Train Loss = 0.5746, Validation Loss = 0.5628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1790/1790 [00:06<00:00, 279.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: Train Loss = 0.5746, Validation Loss = 0.5663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1790/1790 [00:06<00:00, 272.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: Train Loss = 0.5762, Validation Loss = 0.6262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1790/1790 [00:06<00:00, 275.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: Train Loss = 0.5752, Validation Loss = 0.5746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1790/1790 [00:06<00:00, 271.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: Train Loss = 0.5708, Validation Loss = 0.5643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1790/1790 [00:06<00:00, 267.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: Train Loss = 0.5719, Validation Loss = 0.5650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1790/1790 [00:06<00:00, 273.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: Train Loss = 0.5762, Validation Loss = 0.5691\n",
      "Took 135.24 seconds to train in total\n",
      "Best Training Loss = 0.5708\n",
      "Training Accuracy = 0.6913\n",
      "Training False Positive = 17095\n",
      "Training False Negative = 577\n",
      "\n",
      "Best Test Loss = 0.5616\n",
      "Test Accuracy = 0.6912\n",
      "Test False Positive = 8418\n",
      "Test False Negative = 289\n"
     ]
    }
   ],
   "source": [
    " # Create training and validation tensors\n",
    "X_train_tensor = torch.from_numpy(X_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train.reshape(-1, 1)).float()\n",
    "X_test_tensor = torch.from_numpy(X_test).float()\n",
    "y_test_tensor = torch.from_numpy(y_test.reshape(-1, 1)).float()\n",
    "\n",
    "# Create tensor dataset for training\n",
    "dataset_train = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "# torch.manual_seed(2298)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "\n",
    "# Create model\n",
    "model = MLP().to(DEVICE)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005) # lr=0.00005 seems best with Adam\n",
    "# Train model\n",
    "start = time()\n",
    "train_loss_history, valid_loss_history = train_mlp(\n",
    "    model, \n",
    "    dataloader_train, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    n_epochs=20, \n",
    "    X_valid=X_test_tensor, \n",
    "    y_valid=y_test_tensor\n",
    ")\n",
    "\n",
    "# Compute accuracy, false positives and false negatives\n",
    "accuracy_train, fpos_train, fneg_train = get_accuracy(model, X_train_tensor, y_train_tensor)\n",
    "accuracy_valid, fpos_valid, fneg_valid = get_accuracy(model, X_test_tensor, y_test_tensor)\n",
    "\n",
    "print(f'Best Training Loss = {np.min(train_loss_history):.4f}')\n",
    "print(f'Training Accuracy = {accuracy_train:.4f}')\n",
    "print(f'Training False Positive = {fpos_train}')\n",
    "print(f'Training False Negative = {fneg_train}')  \n",
    "\n",
    "print(f'\\nBest Test Loss = {np.min(valid_loss_history):.4f}')\n",
    "print(f'Test Accuracy = {accuracy_valid:.4f}')\n",
    "print(f'Test False Positive = {fpos_valid}')\n",
    "print(f'Test False Negative = {fneg_valid}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
